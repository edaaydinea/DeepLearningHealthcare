{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Difference Between Graph Convolutional Network (GCN) and Graph Attention Network (GAT)\n",
    "- **Graph Convolutional Network (GCN)**:\n",
    "  - Aggregates features from neighboring nodes based on a weighted sum, with the weights determined by the graph structure (e.g., degree of the nodes or adjacency matrix).\n",
    "  - Assumes all neighbors have equal importance.\n",
    "\n",
    "- **Graph Attention Network (GAT)**:\n",
    "  - Uses attention mechanisms to assign different weights to different neighbors during feature aggregation, allowing the model to focus on more important nodes in the graph.\n",
    "\n",
    "### 2. Applications for Graph Neural Networks (multiple correct choices):\n",
    "- **(a) Node classification** ✔️\n",
    "- **(b) Link prediction** ✔️\n",
    "- **(c) Graph generation** ✔️\n",
    "- **(d) Anomaly detection** ✔️\n",
    "- **(e) Graph property prediction** ✔️\n",
    "- **(f) Community detection** ✔️\n",
    "\n",
    "### 3. Challenges of Using Neural Networks on Graphs (multiple correct choices):\n",
    "- **(a) Arbitrary size** ✔️ (Graphs can have varying numbers of nodes and edges)\n",
    "- **(b) No fixed node ordering** ✔️ (Nodes in a graph are unordered, unlike sequences)\n",
    "- **(c) Dynamic updates** ✔️ (Graph structures can change over time)\n",
    "- **(d) Heterogeneous features** ✔️ (Nodes and edges can have different types of features)\n",
    "- **(e) Small sample size** ✔️ (Graph datasets often have fewer labeled examples)\n",
    "\n",
    "### 4. Which is Not Part of the Input to Graph Neural Networks?\n",
    "- **(d) Importance weights of nodes** ❌  \n",
    "  Nodes, edges, and node features are the main inputs, while importance weights are typically learned (e.g., via attention mechanisms).\n",
    "\n",
    "### 5. Which is NOT a Computational Step in Graph Neural Networks?\n",
    "- **(d) Iteratively update the underlying graph structure** ❌  \n",
    "  GNNs operate on a fixed graph structure and do not change it during training. The other options are valid steps.\n",
    "\n",
    "### 6. What is NOT True About GCN Model?\n",
    "- **(d) The number of parameters in GCN is proportional to the graph size** ❌  \n",
    "  The number of parameters in GCN is **independent** of the graph size, as they depend on the size of the node feature vectors and the layers of the network.\n",
    "\n",
    "### 7. Message Passing Update for Node C in MPNN (Fig. 10.4)\n",
    "- **(b) \\( M_t(h_C, h_A, e_{CA}) + M_t(h_C, h_B, e_{CB}) + M_t(h_C, h_E, e_{CE}) \\)** ✔️  \n",
    "  This accounts for all the neighbors of node C, including nodes A, B, and E.\n",
    "\n",
    "### 8. What is NOT True About Read-Out Operation in MPNN?\n",
    "- **(d) Read-out operation is the most expensive step in training MPNN** ❌  \n",
    "  The read-out operation (which generates graph-level embeddings) is generally computationally cheap compared to the message-passing steps.\n",
    "\n",
    "### 9. What is NOT True About GAT Model?\n",
    "- **(c) Attention weights are on all pairs of nodes in the graph** ❌  \n",
    "  GAT computes attention weights only on neighboring nodes, not on all pairs of nodes in the graph.\n",
    "\n",
    "### 10. Different Node Types Used in Polypharmacy Network (Sect. 10.8) (multiple correct choices):\n",
    "- **(a) Drug molecules** ✔️\n",
    "- **(b) Protein targets** ✔️\n",
    "- **(c) Diseases** ✔️\n",
    "- **(d) Side effects** ✔️\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
