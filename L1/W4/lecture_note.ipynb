{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Neuron Basics\n",
    "\n",
    "This lecture provides an introduction to deep neural networks (DNNs), starting with the basic unit, a single neuron, and progressively covering the components, the forward and backward passes, and applications in healthcare.\n",
    "\n",
    "### **Key Concepts:**\n",
    "\n",
    "1. **Neuron Structure:**\n",
    "   - A **neuron** is a computational unit that receives inputs, $x_1, x_2, \\dots, x_n$, each associated with weights, $w_1, w_2, \\dots, w_n$, and a bias term $b$.\n",
    "   - The neuron computes an intermediate output, $z$, which is the **linear combination** of inputs and weights plus the bias: \n",
    "   $$z = \\sum_{i=1}^{n} w_i \\cdot x_i + b$$\n",
    "   - This output $z$ is then passed through a **non-linear activation function** $g$, producing the final output $y$:\n",
    "   $$y = g(z)$$\n",
    "   - The goal is to learn the weights $w_i$ and bias term $b$ to approximate the target $y$, which could represent a binary classification (e.g., disease prediction) or a numerical regression output.\n",
    "\n",
    "2. **Activation Functions:**\n",
    "   Activation functions introduce non-linearity, allowing neural networks to model complex relationships. The most popular activation functions are:\n",
    "   \n",
    "   - **Sigmoid Function:**\n",
    "     $$\\sigma(x) = \\frac{1}{1 + e^{-x}}$$\n",
    "     - **Output Range:** [0, 1]\n",
    "     - **Use Case:** Often used for binary classification (e.g., predicting the probability of a heart disease).\n",
    "     - **Problem:** The **vanishing gradient problem** occurs when the function saturates (output close to 0 or 1), leading to gradients near zero, which hinders the training process.\n",
    "\n",
    "   - **Tanh Function:**\n",
    "     $$\\text{tanh}(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}} = 2\\sigma(2x) - 1$$\n",
    "     - **Output Range:** [-1, 1]\n",
    "     - **Use Case:** Similar to sigmoid but with outputs scaled to range [-1, 1].\n",
    "     - **Problem:** Still suffers from the vanishing gradient problem, especially when inputs are far from zero.\n",
    "\n",
    "   - **ReLU (Rectified Linear Unit):**\n",
    "     $$\\text{ReLU}(x) = \\max(0, x)$$\n",
    "     - **Output Range:** [0, ∞)\n",
    "     - **Use Case:** Popular in deep networks due to its simplicity and efficiency.\n",
    "     - **Advantage:** Does not suffer from the vanishing gradient problem for positive inputs, as the gradient remains constant.\n",
    "\n",
    "3. **Choosing Activation Functions:**\n",
    "   - The choice of activation function depends on the specific task and neural network architecture.\n",
    "   - **Sigmoid** is typically used in the output layer for binary classification tasks.\n",
    "   - **Tanh** can be useful in hidden layers where the output needs to range between negative and positive values.\n",
    "   - **ReLU** is commonly used in hidden layers due to its efficiency and ability to mitigate the vanishing gradient problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Single Neuron: SGD\n",
    "\n",
    "In this section of the lecture, you’re diving deeper into how a single neuron in a neural network operates, and how optimization methods, particularly gradient descent and its variant stochastic gradient descent (SGD), are used to train neural networks.\n",
    "\n",
    "### **Single Neuron Operation:**\n",
    "\n",
    "1. **Computation Breakdown:**\n",
    "   - **Linear Combination:**\n",
    "     $$z = \\sum_{i=1}^{n} w_i \\cdot x_i + b$$\n",
    "     This computes an intermediate value $z$ by summing the weighted inputs and adding a bias term.\n",
    "   - **Nonlinear Transformation:**\n",
    "     $$y = g(z)$$\n",
    "     The intermediate value $z$ is passed through an activation function $g$ to produce the final output $y$.\n",
    "\n",
    "2. **Training the Neuron:**\n",
    "   - **Loss Function:**\n",
    "     The goal of training is to adjust the weights $w_i$ and bias $b$ so that the output $y$ is close to a target label $t$. A common loss function used is the squared loss:\n",
    "     $$\\text{Loss} = \\frac{1}{2}(y - t)^2$$\n",
    "     This measures the difference between the predicted output $y$ and the target $t$.\n",
    "\n",
    "### **Optimization with Gradient Descent:**\n",
    "\n",
    "1. **Gradient Descent Overview:**\n",
    "   - **Objective:**\n",
    "     To minimize the loss function by adjusting the model parameters (weights and biases) based on the gradient of the loss function.\n",
    "   - **Steps:**\n",
    "     1. **Define the Likelihood Function:**\n",
    "        For a given model, specify how likely the observed data is under different parameter settings. Often, the log-likelihood is used for numerical stability and simplicity:\n",
    "        $$\\text{Log-Likelihood} = \\log(\\text{Likelihood})$$\n",
    "     2. **Compute the Gradient:**\n",
    "        Calculate the gradient (partial derivatives) of the log-likelihood with respect to each parameter. This involves finding how changes in the parameters affect the likelihood:\n",
    "        $$\\text{Gradient} = \\frac{\\partial (\\text{Log-Likelihood})}{\\partial \\theta}$$\n",
    "     3. **Update Parameters:**\n",
    "        Adjust the parameters in the direction opposite to the gradient to reduce the loss:\n",
    "        $$\\theta_{\\text{new}} = \\theta_{\\text{old}} - \\eta \\cdot \\text{Gradient}$$\n",
    "        Here, $\\eta$ is the learning rate, a hyperparameter that controls the step size of each update.\n",
    "\n",
    "2. **Stochastic Gradient Descent (SGD):**\n",
    "   - **Challenge with Large Datasets:**\n",
    "     Computing gradients over the entire dataset can be computationally expensive. SGD addresses this by updating parameters using a random subset of data points:\n",
    "     - **Mini-Batch Gradient Descent:** Uses a subset (mini-batch) of the dataset to compute gradients.\n",
    "     - **Online Gradient Descent:** Uses one data point at a time (stochastic updates).\n",
    "   - **SGD Algorithm:**\n",
    "     1. **Initialize Parameters:**\n",
    "        Start with small random values for weights $w$ and bias $b$.\n",
    "     2. **Iterate:**\n",
    "        For each iteration, pick a data point or mini-batch, compute the gradient of the loss with respect to parameters, and update parameters:\n",
    "        $$w_{\\text{new}} = w_{\\text{old}} - \\eta \\cdot \\frac{\\partial \\text{Loss}}{\\partial w}$$\n",
    "        $$b_{\\text{new}} = b_{\\text{old}} - \\eta \\cdot \\frac{\\partial \\text{Loss}}{\\partial b}$$\n",
    "     3. **Repeat:**\n",
    "        Continue until the parameters converge or a stopping criterion is met.\n",
    "\n",
    "### **Summary:**\n",
    "\n",
    "- **Single Neuron:**\n",
    "  - Consists of a linear combination of inputs and a non-linear activation function.\n",
    "  - Training involves minimizing a loss function to make predictions as close to the target values as possible.\n",
    "\n",
    "- **Gradient Descent:**\n",
    "  - An optimization technique used to find the parameter values that minimize the loss function.\n",
    "  - Involves computing gradients and updating parameters iteratively.\n",
    "  \n",
    "- **Stochastic Gradient Descent (SGD):**\n",
    "  - A variant of gradient descent that handles large datasets efficiently by updating parameters based on a subset of data points.\n",
    "\n",
    "These concepts lay the groundwork for understanding how more complex neural networks are trained and optimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward and Backward Computation\n",
    "\n",
    "To train a single neuron effectively, you need to perform two critical steps: the forward pass and the backward pass. Here’s a detailed breakdown of each step and how they work together to update the neuron’s parameters:\n",
    "\n",
    "### **1. Forward Pass:**\n",
    "\n",
    "**Objective:** Compute the output $y$ of the neuron and the loss.\n",
    "\n",
    "- **Linear Combination:**\n",
    "  $$\n",
    "  z = \\sum_{i=1}^{n} w_i \\cdot x_i + b\n",
    "  $$\n",
    "  Here, $z$ is the weighted sum of inputs $x_i$ plus the bias term $b$.\n",
    "\n",
    "- **Nonlinear Activation:**\n",
    "  Apply an activation function $g$ to $z$:\n",
    "  $$\n",
    "  y = g(z)\n",
    "  $$\n",
    "  For example, if the activation function is a sigmoid:\n",
    "  $$\n",
    "  y = \\frac{1}{1 + e^{-z}}\n",
    "  $$\n",
    "\n",
    "- **Loss Function:**\n",
    "  Compute the loss $L$, which measures how far the output $y$ is from the target $t$. For a squared loss function:\n",
    "  $$\n",
    "  L = \\frac{1}{2} (y - t)^2\n",
    "  $$\n",
    "\n",
    "### **2. Backward Pass:**\n",
    "\n",
    "**Objective:** Compute the gradients of the loss with respect to each parameter and use these gradients to update the parameters.\n",
    "\n",
    "- **Compute Gradients:**\n",
    "  Using the chain rule of calculus, the gradient of the loss function $L$ with respect to each parameter $w_i$ and the bias term $b$ is calculated.\n",
    "\n",
    "  **For Weight $w_i$:**\n",
    "\n",
    "  1. **Derivative of Loss with Respect to Output $y$:**\n",
    "     $$\n",
    "     \\frac{\\partial L}{\\partial y} = y - t\n",
    "     $$\n",
    "     Here, $L$ is the loss function, and $y$ is the neuron’s output.\n",
    "\n",
    "  2. **Derivative of Output $y$ with Respect to $z$:**\n",
    "     $$\n",
    "     \\frac{\\partial y}{\\partial z} = y \\cdot (1 - y)\n",
    "     $$\n",
    "     This derivative comes from the sigmoid activation function.\n",
    "\n",
    "  3. **Derivative of $z$ with Respect to $w_i$:**\n",
    "     $$\n",
    "     \\frac{\\partial z}{\\partial w_i} = x_i\n",
    "     $$\n",
    "     Since $z$ is the weighted sum, the derivative with respect to $w_i$ is the input $x_i$.\n",
    "\n",
    "  Combine these derivatives using the chain rule:\n",
    "  $$\n",
    "  \\frac{\\partial L}{\\partial w_i} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial y}{\\partial z} \\cdot \\frac{\\partial z}{\\partial w_i}\n",
    "  $$\n",
    "  Substituting in:\n",
    "  $$\n",
    "  \\frac{\\partial L}{\\partial w_i} = (y - t) \\cdot y \\cdot (1 - y) \\cdot x_i\n",
    "  $$\n",
    "\n",
    "  **For Bias $b$:**\n",
    "\n",
    "  1. **Derivative of Loss with Respect to Output $y$:**\n",
    "     $$\n",
    "     \\frac{\\partial L}{\\partial y} = y - t\n",
    "     $$\n",
    "\n",
    "  2. **Derivative of Output $y$ with Respect to $z$:**\n",
    "     $$\n",
    "     \\frac{\\partial y}{\\partial z} = y \\cdot (1 - y)\n",
    "     $$\n",
    "\n",
    "  3. **Derivative of $z$ with Respect to Bias $b$:**\n",
    "     $$\n",
    "     \\frac{\\partial z}{\\partial b} = 1\n",
    "     $$\n",
    "     The derivative of $z$ with respect to $b$ is 1 because $b$ is added directly to $z$.\n",
    "\n",
    "  Combine these derivatives:\n",
    "  $$\n",
    "  \\frac{\\partial L}{\\partial b} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial y}{\\partial z} \\cdot \\frac{\\partial z}{\\partial b}\n",
    "  $$\n",
    "  Substituting in:\n",
    "  $$\n",
    "  \\frac{\\partial L}{\\partial b} = (y - t) \\cdot y \\cdot (1 - y)\n",
    "  $$\n",
    "\n",
    "### **3. Update Parameters:**\n",
    "\n",
    "Use the gradients computed from the backward pass to update the weights $w_i$ and bias $b$ using stochastic gradient descent (SGD):\n",
    "\n",
    "- **Weight Update:**\n",
    "  $$\n",
    "  w_i \\leftarrow w_i - \\eta \\cdot \\frac{\\partial L}{\\partial w_i}\n",
    "  $$\n",
    "  where $\\eta$ is the learning rate.\n",
    "\n",
    "- **Bias Update:**\n",
    "  $$\n",
    "  b \\leftarrow b - \\eta \\cdot \\frac{\\partial L}{\\partial b}\n",
    "  $$\n",
    "\n",
    "### **Automatic Differentiation:**\n",
    "\n",
    "Modern deep learning frameworks handle the gradient computations automatically using automatic differentiation, which simplifies the implementation of neural network training. This allows practitioners to focus more on the architecture and less on the detailed computation of gradients.\n",
    "\n",
    "### **Summary:**\n",
    "\n",
    "- **Forward Pass:** Compute $z$, apply the activation function to get $y$, and calculate the loss $L$.\n",
    "- **Backward Pass:** Compute gradients of $L$ with respect to parameters $w_i$ and $b$ using the chain rule.\n",
    "- **Parameter Update:** Adjust parameters using gradients and learning rate.\n",
    "\n",
    "This process of forward and backward passes allows the network to learn and adjust its weights and biases to minimize the loss function over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Neural Network\n",
    "\n",
    "### Multilayer Neural Networks\n",
    "\n",
    "A neural network is built by connecting neurons across multiple layers, where each neuron's output becomes the input to the next layer. This structure allows the network to learn complex functions by stacking layers of neurons. Here’s a detailed breakdown of how to compute the forward pass in a multilayer neural network and how to represent these computations efficiently.\n",
    "\n",
    "### **Network Structure**\n",
    "\n",
    "Consider a simple multilayer neural network with the following layers:\n",
    "\n",
    "1. **Input Layer (Layer 1):**\n",
    "   - **Units:** $x_1, x_2, x_3$ (input features) and one bias unit.\n",
    "\n",
    "2. **Hidden Layer (Layer 2):**\n",
    "   - **Units:** $h_1, h_2, h_3$ (hidden neurons) and one bias unit.\n",
    "\n",
    "3. **Output Layer (Layer 3):**\n",
    "   - **Unit:** $y$ (output neuron).\n",
    "\n",
    "### **Forward Pass Computation**\n",
    "\n",
    "**Step-by-Step Forward Pass:**\n",
    "\n",
    "1. **Compute Linear Combinations in Hidden Layer:**\n",
    "\n",
    "   Each hidden unit computes a linear combination of inputs plus a bias term:\n",
    "   $$\n",
    "   z_j^{(2)} = \\sum_{i=1}^{n} w_{ji}^{(1)} \\cdot x_i + b_j^{(1)}\n",
    "   $$\n",
    "   - $z_j^{(2)}$ is the linear combination for hidden unit $h_j$ from layer 1.\n",
    "   - $w_{ji}^{(1)}$ is the weight from input unit $x_i$ to hidden unit $h_j$.\n",
    "   - $b_j^{(1)}$ is the bias term for hidden unit $h_j$.\n",
    "\n",
    "2. **Apply Activation Function to Hidden Units:**\n",
    "\n",
    "   Apply a nonlinear activation function $g^{(2)}$ (e.g., sigmoid or ReLU) to $z_j^{(2)}$:\n",
    "   $$\n",
    "   a_j^{(2)} = g^{(2)}(z_j^{(2)})\n",
    "   $$\n",
    "   - $a_j^{(2)}$ is the output of hidden unit $h_j$.\n",
    "\n",
    "3. **Compute Linear Combination in Output Layer:**\n",
    "\n",
    "   Use the outputs from the hidden layer as inputs to the output layer:\n",
    "   $$\n",
    "   z^{(3)} = \\sum_{j=1}^{m} w_{j}^{(2)} \\cdot a_j^{(2)} + b^{(2)}\n",
    "   $$\n",
    "   - $z^{(3)}$ is the linear combination for the output unit.\n",
    "   - $w_{j}^{(2)}$ is the weight from hidden unit $h_j$ to the output unit $y$.\n",
    "   - $b^{(2)}$ is the bias term for the output unit.\n",
    "\n",
    "4. **Apply Activation Function to Output Unit:**\n",
    "\n",
    "   Apply an activation function $g^{(3)}$ to $z^{(3)}$:\n",
    "   $$\n",
    "   y = g^{(3)}(z^{(3)})\n",
    "   $$\n",
    "   - $y$ is the final output of the network.\n",
    "\n",
    "### **Matrix Notation for Efficiency**\n",
    "\n",
    "For efficient computation, especially with large networks, we use matrix operations:\n",
    "\n",
    "1. **Matrix Representation for Hidden Layer:**\n",
    "\n",
    "   - **Weights Matrix:** $W^{(1)}$ (matrix of weights connecting input layer to hidden layer).\n",
    "   - **Bias Vector:** $b^{(1)}$.\n",
    "\n",
    "   Compute:\n",
    "   $$\n",
    "   z^{(2)} = W^{(1)} \\cdot x + b^{(1)}\n",
    "   $$\n",
    "   Apply activation function element-wise:\n",
    "   $$\n",
    "   a^{(2)} = g^{(2)}(z^{(2)})\n",
    "   $$\n",
    "\n",
    "2. **Matrix Representation for Output Layer:**\n",
    "\n",
    "   - **Weights Matrix:** $W^{(2)}$ (matrix of weights connecting hidden layer to output layer).\n",
    "   - **Bias Term:** $b^{(2)}$.\n",
    "\n",
    "   Compute:\n",
    "   $$\n",
    "   z^{(3)} = W^{(2)} \\cdot a^{(2)} + b^{(2)}\n",
    "   $$\n",
    "   Apply activation function:\n",
    "   $$\n",
    "   y = g^{(3)}(z^{(3)})\n",
    "   $$\n",
    "\n",
    "### **General Form for Multiple Layers**\n",
    "\n",
    "For a neural network with $L$ layers, the forward pass computation from layer $l$ to layer $l+1$ is given by:\n",
    "\n",
    "1. **Linear Combination:**\n",
    "   $$\n",
    "   z^{(l+1)} = W^{(l)} \\cdot a^{(l)} + b^{(l)}\n",
    "   $$\n",
    "\n",
    "2. **Activation Function:**\n",
    "   $$\n",
    "   a^{(l+1)} = g^{(l+1)}(z^{(l+1)})\n",
    "   $$\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "- **Forward Pass:** Involves computing linear combinations and applying activation functions layer by layer.\n",
    "- **Matrix Notation:** Used for efficient computation, particularly in large networks and when using hardware accelerators like GPUs.\n",
    "- **General Form:** Provides a compact and scalable way to represent neural network computations.\n",
    "\n",
    "This process of computing the forward pass is crucial for both scoring new data points and training the network using backpropagation. The matrix operations ensure that the computations are performed efficiently, leveraging modern computational resources."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
